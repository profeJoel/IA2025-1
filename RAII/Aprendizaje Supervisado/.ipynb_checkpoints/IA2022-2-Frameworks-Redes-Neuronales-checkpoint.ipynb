{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "X78Er0eD-Npw"
   },
   "source": [
    "###Descripción del Dataset PIMA DIABETES\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "id": "LEJSU1zp80rs"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PhCm9U64-iyx",
    "outputId": "518d8682-d445-426b-bb6d-ac8319986638"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(768, 9)\n"
     ]
    }
   ],
   "source": [
    "diabetes = pd.read_csv('diabetes.csv')\n",
    "print(diabetes.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 284
    },
    "id": "XFoVtHW8-7s9",
    "outputId": "6303e501-e55d-41cb-aee3-2b77d075e388"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pregnancies</th>\n",
       "      <th>Glucose</th>\n",
       "      <th>BloodPressure</th>\n",
       "      <th>SkinThickness</th>\n",
       "      <th>Insulin</th>\n",
       "      <th>BMI</th>\n",
       "      <th>DiabetesPedigreeFunction</th>\n",
       "      <th>Age</th>\n",
       "      <th>Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "      <td>768.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.845052</td>\n",
       "      <td>120.894531</td>\n",
       "      <td>69.105469</td>\n",
       "      <td>20.536458</td>\n",
       "      <td>79.799479</td>\n",
       "      <td>31.992578</td>\n",
       "      <td>0.471876</td>\n",
       "      <td>33.240885</td>\n",
       "      <td>0.348958</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>3.369578</td>\n",
       "      <td>31.972618</td>\n",
       "      <td>19.355807</td>\n",
       "      <td>15.952218</td>\n",
       "      <td>115.244002</td>\n",
       "      <td>7.884160</td>\n",
       "      <td>0.331329</td>\n",
       "      <td>11.760232</td>\n",
       "      <td>0.476951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>21.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>62.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>27.300000</td>\n",
       "      <td>0.243750</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>117.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>30.500000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>0.372500</td>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>140.250000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>127.250000</td>\n",
       "      <td>36.600000</td>\n",
       "      <td>0.626250</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>17.000000</td>\n",
       "      <td>199.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>99.000000</td>\n",
       "      <td>846.000000</td>\n",
       "      <td>67.100000</td>\n",
       "      <td>2.420000</td>\n",
       "      <td>81.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Pregnancies     Glucose  BloodPressure  SkinThickness     Insulin  \\\n",
       "count   768.000000  768.000000     768.000000     768.000000  768.000000   \n",
       "mean      3.845052  120.894531      69.105469      20.536458   79.799479   \n",
       "std       3.369578   31.972618      19.355807      15.952218  115.244002   \n",
       "min       0.000000    0.000000       0.000000       0.000000    0.000000   \n",
       "25%       1.000000   99.000000      62.000000       0.000000    0.000000   \n",
       "50%       3.000000  117.000000      72.000000      23.000000   30.500000   \n",
       "75%       6.000000  140.250000      80.000000      32.000000  127.250000   \n",
       "max      17.000000  199.000000     122.000000      99.000000  846.000000   \n",
       "\n",
       "              BMI  DiabetesPedigreeFunction         Age     Outcome  \n",
       "count  768.000000                768.000000  768.000000  768.000000  \n",
       "mean    31.992578                  0.471876   33.240885    0.348958  \n",
       "std      7.884160                  0.331329   11.760232    0.476951  \n",
       "min      0.000000                  0.078000   21.000000    0.000000  \n",
       "25%     27.300000                  0.243750   24.000000    0.000000  \n",
       "50%     32.000000                  0.372500   29.000000    0.000000  \n",
       "75%     36.600000                  0.626250   41.000000    1.000000  \n",
       "max     67.100000                  2.420000   81.000000    1.000000  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diabetes.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 195
    },
    "id": "DteDP2qn_EoQ",
    "outputId": "5129e31f-4fdc-4aaa-f3b0-df0b54d1591d"
   },
   "outputs": [],
   "source": [
    "diabetes.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YO1RKBiQ_Zh1",
    "outputId": "abefbb36-42a2-45a1-d2fa-146ce523b446"
   },
   "outputs": [],
   "source": [
    "diabetes.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "R9WWp1gT_kla"
   },
   "source": [
    "###Análisis Exploratorio de Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "jeRALISj_qG9",
    "outputId": "954ca478-5c65-4abd-9ffb-1b8d26c3bb33"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.pairplot(diabetes, hue = 'Outcome', height= 2, palette='colorblind');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "z2RrS2EHANRM",
    "outputId": "59d264de-4063-4a2f-e227-ab06e59f48cc"
   },
   "outputs": [],
   "source": [
    "#Para entender el comportamiento de la gráfica de pares\n",
    "import seaborn as sns\n",
    "sns.pairplot(diabetes, hue = 'Pregnancies', height= 2, palette='colorblind');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 667
    },
    "id": "W_ubzmNfA0zX",
    "outputId": "14694015-b77e-4619-e985-215142e976e8"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(10,10))  \n",
    "sns.heatmap(diabetes.corr(), annot= True, square=True,ax=ax);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f4wyBk3DCHVl"
   },
   "source": [
    "###Preparación de los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_jakOO-kChq5",
    "outputId": "894e7060-8fd1-4eb2-c889-aca607c02f5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(537, 9) (231, 9)\n"
     ]
    }
   ],
   "source": [
    "#Separación entre entrenamiento y test\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train, test = train_test_split(diabetes, stratify = diabetes['Outcome'], test_size = 0.3, random_state = 100)\n",
    "\n",
    "print(train.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n47D9i3MCJWs",
    "outputId": "5e908d92-fc8e-417b-9c3e-48b3f731b233"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(537, 8) (537,)\n",
      "(231, 8) (231,)\n"
     ]
    }
   ],
   "source": [
    "#Separación de los conjuntos de datos\n",
    "X_train = np.c_[train['Pregnancies'], train['Glucose'],train['BloodPressure'],train['SkinThickness'],train['Insulin'],train['BMI'],train['DiabetesPedigreeFunction'],train['Age']]\n",
    "y_train = train['Outcome'].values\n",
    "\n",
    "X_test = np.c_[test['Pregnancies'], test['Glucose'],test['BloodPressure'],test['SkinThickness'],test['Insulin'],test['BMI'],test['DiabetesPedigreeFunction'],test['Age']]\n",
    "y_test = test['Outcome'].values\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fq1DoWhPDPYA"
   },
   "source": [
    "###Modelo con  Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W7fy86zHDOwM",
    "outputId": "624fad9f-72c6-4628-ecee-e2c7f4af4bed"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;,\n",
       "              hidden_layer_sizes=(64, 32, 16, 8, 4, 2, 1), max_iter=100000000,\n",
       "              solver=&#x27;sgd&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier(activation=&#x27;logistic&#x27;,\n",
       "              hidden_layer_sizes=(64, 32, 16, 8, 4, 2, 1), max_iter=100000000,\n",
       "              solver=&#x27;sgd&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MLPClassifier(activation='logistic',\n",
       "              hidden_layer_sizes=(64, 32, 16, 8, 4, 2, 1), max_iter=100000000,\n",
       "              solver='sgd')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definición del modelo\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "red_skl = MLPClassifier(hidden_layer_sizes = (64,32,16,8,4,2,1), activation = 'logistic', solver = 'sgd', max_iter = 100000000)\n",
    "red_skl.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XVjxT85dFEH9",
    "outputId": "aa931ab8-13dd-45cc-fa73-9ce8e9a68160"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento en Entrenamiento\n",
      "[[350   0]\n",
      " [187   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79       350\n",
      "           1       0.00      0.00      0.00       187\n",
      "\n",
      "    accuracy                           0.65       537\n",
      "   macro avg       0.33      0.50      0.39       537\n",
      "weighted avg       0.42      0.65      0.51       537\n",
      "\n",
      "Rendimiento en Testeo\n",
      "[[150   0]\n",
      " [ 81   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79       150\n",
      "           1       0.00      0.00      0.00        81\n",
      "\n",
      "    accuracy                           0.65       231\n",
      "   macro avg       0.32      0.50      0.39       231\n",
      "weighted avg       0.42      0.65      0.51       231\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/joelsebastiantorrescarrasco/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/joelsebastiantorrescarrasco/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/joelsebastiantorrescarrasco/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/joelsebastiantorrescarrasco/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/joelsebastiantorrescarrasco/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/joelsebastiantorrescarrasco/anaconda3/lib/python3.11/site-packages/sklearn/metrics/_classification.py:1469: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "#evaluación\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "y_train_pred = red_skl.predict(X_train)\n",
    "y_test_pred = red_skl.predict(X_test)\n",
    "\n",
    "print(\"Rendimiento en Entrenamiento\")\n",
    "print(confusion_matrix(y_train, y_train_pred))\n",
    "print(classification_report(y_train, y_train_pred))\n",
    "\n",
    "\n",
    "print(\"Rendimiento en Testeo\")\n",
    "print(confusion_matrix(y_test, y_test_pred))\n",
    "print(classification_report(y_test, y_test_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RFow6M3OEvYL"
   },
   "source": [
    "###Crear Modelo con PyTorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "id": "LaSt8A9wEuS-"
   },
   "outputs": [],
   "source": [
    "#Importar los módulos\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "X_train_t = torch.FloatTensor(X_train)\n",
    "X_test_t = torch.FloatTensor(X_test)\n",
    "\n",
    "y_train_t = torch.LongTensor(y_train)\n",
    "y_test_t = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "id": "2ynBCXhwFtjb"
   },
   "outputs": [],
   "source": [
    "#Crear modelo\n",
    "class red_torch(nn.Module):\n",
    "  def __init__(self, input_features = 8, hidden1 = 16, hidden2 = 32, hidden3 = 16, out_features = 2):\n",
    "    super().__init__()\n",
    "    self.f_conected1 = nn.Linear(input_features, hidden1)\n",
    "    self.f_conected2 = nn.Linear(hidden1, hidden2)\n",
    "    self.f_conected3 = nn.Linear(hidden2, hidden3)\n",
    "    self.out = nn.Linear(hidden3, out_features)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = F.relu(self.f_conected1(x))\n",
    "    x = F.relu(self.f_conected2(x))\n",
    "    x = F.relu(self.f_conected3(x))\n",
    "    x = self.out(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "P0Hxpy76IGjM",
    "outputId": "1623bc16-45b3-448b-aa21-341987c1f94c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x32274fa00>"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#instanciación del modelo\n",
    "torch.manual_seed(100)\n",
    "red_pytorch = red_torch()\n",
    "red_pytorch.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "73ctX14oIaW_",
    "outputId": "63b07bf5-8b4e-4fee-efff-d44b6f53e6f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generacion: 1 con costo: 1.0893666744232178\n",
      "Generacion: 11 con costo: 0.8439814448356628\n",
      "Generacion: 21 con costo: 0.7496344447135925\n",
      "Generacion: 31 con costo: 0.7069353461265564\n",
      "Generacion: 41 con costo: 0.685757577419281\n",
      "Generacion: 51 con costo: 0.6746235489845276\n",
      "Generacion: 61 con costo: 0.6676879525184631\n",
      "Generacion: 71 con costo: 0.6629685759544373\n",
      "Generacion: 81 con costo: 0.6594529747962952\n",
      "Generacion: 91 con costo: 0.65700364112854\n",
      "Generacion: 101 con costo: 0.6552020907402039\n",
      "Generacion: 111 con costo: 0.6541281938552856\n",
      "Generacion: 121 con costo: 0.6531376242637634\n",
      "Generacion: 131 con costo: 0.6520599722862244\n",
      "Generacion: 141 con costo: 0.6510962843894958\n",
      "Generacion: 151 con costo: 0.6503164172172546\n",
      "Generacion: 161 con costo: 0.6496196985244751\n",
      "Generacion: 171 con costo: 0.6489391922950745\n",
      "Generacion: 181 con costo: 0.6482264995574951\n",
      "Generacion: 191 con costo: 0.6476097702980042\n",
      "Generacion: 201 con costo: 0.647033154964447\n",
      "Generacion: 211 con costo: 0.6465743780136108\n",
      "Generacion: 221 con costo: 0.6461347937583923\n",
      "Generacion: 231 con costo: 0.6456842422485352\n",
      "Generacion: 241 con costo: 0.6452623605728149\n",
      "Generacion: 251 con costo: 0.6448675394058228\n",
      "Generacion: 261 con costo: 0.6445099115371704\n",
      "Generacion: 271 con costo: 0.6441527009010315\n",
      "Generacion: 281 con costo: 0.6438080668449402\n",
      "Generacion: 291 con costo: 0.6434687376022339\n",
      "Generacion: 301 con costo: 0.6431302428245544\n",
      "Generacion: 311 con costo: 0.6427907943725586\n",
      "Generacion: 321 con costo: 0.6424517631530762\n",
      "Generacion: 331 con costo: 0.6421186327934265\n",
      "Generacion: 341 con costo: 0.6417806148529053\n",
      "Generacion: 351 con costo: 0.6414428353309631\n",
      "Generacion: 361 con costo: 0.6411153674125671\n",
      "Generacion: 371 con costo: 0.640788733959198\n",
      "Generacion: 381 con costo: 0.6404719948768616\n",
      "Generacion: 391 con costo: 0.6401477456092834\n",
      "Generacion: 401 con costo: 0.6398256421089172\n",
      "Generacion: 411 con costo: 0.6395033597946167\n",
      "Generacion: 421 con costo: 0.6391803026199341\n",
      "Generacion: 431 con costo: 0.6388563513755798\n",
      "Generacion: 441 con costo: 0.6385288238525391\n",
      "Generacion: 451 con costo: 0.6381982564926147\n",
      "Generacion: 461 con costo: 0.6378653645515442\n",
      "Generacion: 471 con costo: 0.6375414729118347\n",
      "Generacion: 481 con costo: 0.6372297406196594\n",
      "Generacion: 491 con costo: 0.6369280815124512\n",
      "Generacion: 501 con costo: 0.6366258859634399\n",
      "Generacion: 511 con costo: 0.636317789554596\n",
      "Generacion: 521 con costo: 0.6360141038894653\n",
      "Generacion: 531 con costo: 0.6357080340385437\n",
      "Generacion: 541 con costo: 0.6354031562805176\n",
      "Generacion: 551 con costo: 0.6350979208946228\n",
      "Generacion: 561 con costo: 0.6348090767860413\n",
      "Generacion: 571 con costo: 0.6345321536064148\n",
      "Generacion: 581 con costo: 0.6342611312866211\n",
      "Generacion: 591 con costo: 0.6339888572692871\n",
      "Generacion: 601 con costo: 0.6337188482284546\n",
      "Generacion: 611 con costo: 0.6334478855133057\n",
      "Generacion: 621 con costo: 0.633170485496521\n",
      "Generacion: 631 con costo: 0.6328923106193542\n",
      "Generacion: 641 con costo: 0.6326189041137695\n",
      "Generacion: 651 con costo: 0.6323454976081848\n",
      "Generacion: 661 con costo: 0.6320731043815613\n",
      "Generacion: 671 con costo: 0.6317986845970154\n",
      "Generacion: 681 con costo: 0.6315233111381531\n",
      "Generacion: 691 con costo: 0.6312507390975952\n",
      "Generacion: 701 con costo: 0.6309836506843567\n",
      "Generacion: 711 con costo: 0.6307169795036316\n",
      "Generacion: 721 con costo: 0.6304509043693542\n",
      "Generacion: 731 con costo: 0.6301873922348022\n",
      "Generacion: 741 con costo: 0.6299346685409546\n",
      "Generacion: 751 con costo: 0.6296886205673218\n",
      "Generacion: 761 con costo: 0.6294374465942383\n",
      "Generacion: 771 con costo: 0.6291887164115906\n",
      "Generacion: 781 con costo: 0.6289450526237488\n",
      "Generacion: 791 con costo: 0.6286993622779846\n",
      "Generacion: 801 con costo: 0.6284596920013428\n",
      "Generacion: 811 con costo: 0.6282121539115906\n",
      "Generacion: 821 con costo: 0.6279634833335876\n",
      "Generacion: 831 con costo: 0.6277076601982117\n",
      "Generacion: 841 con costo: 0.6274584531784058\n",
      "Generacion: 851 con costo: 0.6272163987159729\n",
      "Generacion: 861 con costo: 0.6269793510437012\n",
      "Generacion: 871 con costo: 0.6267486810684204\n",
      "Generacion: 881 con costo: 0.6265208125114441\n",
      "Generacion: 891 con costo: 0.6262972950935364\n",
      "Generacion: 901 con costo: 0.6260833144187927\n",
      "Generacion: 911 con costo: 0.6258721947669983\n",
      "Generacion: 921 con costo: 0.6256518959999084\n",
      "Generacion: 931 con costo: 0.6254241466522217\n",
      "Generacion: 941 con costo: 0.6252051591873169\n",
      "Generacion: 951 con costo: 0.6249843239784241\n",
      "Generacion: 961 con costo: 0.6247614622116089\n",
      "Generacion: 971 con costo: 0.6245404481887817\n",
      "Generacion: 981 con costo: 0.6243170499801636\n",
      "Generacion: 991 con costo: 0.6240938305854797\n",
      "Generacion: 1001 con costo: 0.6238740682601929\n",
      "Generacion: 1011 con costo: 0.6236613392829895\n",
      "Generacion: 1021 con costo: 0.6234476566314697\n",
      "Generacion: 1031 con costo: 0.6232377290725708\n",
      "Generacion: 1041 con costo: 0.6230268478393555\n",
      "Generacion: 1051 con costo: 0.6228180527687073\n",
      "Generacion: 1061 con costo: 0.6226089596748352\n",
      "Generacion: 1071 con costo: 0.6223927140235901\n",
      "Generacion: 1081 con costo: 0.6221855878829956\n",
      "Generacion: 1091 con costo: 0.6219795346260071\n",
      "Generacion: 1101 con costo: 0.621777355670929\n",
      "Generacion: 1111 con costo: 0.6215764880180359\n",
      "Generacion: 1121 con costo: 0.6213754415512085\n",
      "Generacion: 1131 con costo: 0.621173620223999\n",
      "Generacion: 1141 con costo: 0.620974063873291\n",
      "Generacion: 1151 con costo: 0.6207775473594666\n",
      "Generacion: 1161 con costo: 0.620581328868866\n",
      "Generacion: 1171 con costo: 0.6203879117965698\n",
      "Generacion: 1181 con costo: 0.6201920509338379\n",
      "Generacion: 1191 con costo: 0.6199911832809448\n",
      "Generacion: 1201 con costo: 0.6197715401649475\n",
      "Generacion: 1211 con costo: 0.6195796728134155\n",
      "Generacion: 1221 con costo: 0.6193852424621582\n",
      "Generacion: 1231 con costo: 0.6191913485527039\n",
      "Generacion: 1241 con costo: 0.6189948320388794\n",
      "Generacion: 1251 con costo: 0.6187981963157654\n",
      "Generacion: 1261 con costo: 0.6186014413833618\n",
      "Generacion: 1271 con costo: 0.6184173822402954\n",
      "Generacion: 1281 con costo: 0.6182399392127991\n",
      "Generacion: 1291 con costo: 0.6180638670921326\n",
      "Generacion: 1301 con costo: 0.6178890466690063\n",
      "Generacion: 1311 con costo: 0.617713212966919\n",
      "Generacion: 1321 con costo: 0.6175387501716614\n",
      "Generacion: 1331 con costo: 0.6173581480979919\n",
      "Generacion: 1341 con costo: 0.617168664932251\n",
      "Generacion: 1351 con costo: 0.6169772744178772\n",
      "Generacion: 1361 con costo: 0.6167917251586914\n",
      "Generacion: 1371 con costo: 0.6166077852249146\n",
      "Generacion: 1381 con costo: 0.6164224743843079\n",
      "Generacion: 1391 con costo: 0.6162363886833191\n",
      "Generacion: 1401 con costo: 0.6160540580749512\n",
      "Generacion: 1411 con costo: 0.6158788204193115\n",
      "Generacion: 1421 con costo: 0.6157029271125793\n",
      "Generacion: 1431 con costo: 0.6155257821083069\n",
      "Generacion: 1441 con costo: 0.6153620481491089\n",
      "Generacion: 1451 con costo: 0.6151981353759766\n",
      "Generacion: 1461 con costo: 0.6150369048118591\n",
      "Generacion: 1471 con costo: 0.6148734092712402\n",
      "Generacion: 1481 con costo: 0.6147090792655945\n",
      "Generacion: 1491 con costo: 0.614543616771698\n",
      "Generacion: 1501 con costo: 0.6143832802772522\n",
      "Generacion: 1511 con costo: 0.6142258048057556\n",
      "Generacion: 1521 con costo: 0.6140697598457336\n",
      "Generacion: 1531 con costo: 0.6139163374900818\n",
      "Generacion: 1541 con costo: 0.6137611269950867\n",
      "Generacion: 1551 con costo: 0.6136066317558289\n",
      "Generacion: 1561 con costo: 0.6134515404701233\n",
      "Generacion: 1571 con costo: 0.6132959127426147\n",
      "Generacion: 1581 con costo: 0.6131434440612793\n",
      "Generacion: 1591 con costo: 0.6129937171936035\n",
      "Generacion: 1601 con costo: 0.6128475069999695\n",
      "Generacion: 1611 con costo: 0.6127023100852966\n",
      "Generacion: 1621 con costo: 0.6125559210777283\n",
      "Generacion: 1631 con costo: 0.612398624420166\n",
      "Generacion: 1641 con costo: 0.6122385859489441\n",
      "Generacion: 1651 con costo: 0.6120694875717163\n",
      "Generacion: 1661 con costo: 0.6119142770767212\n",
      "Generacion: 1671 con costo: 0.6117615699768066\n",
      "Generacion: 1681 con costo: 0.6116129159927368\n",
      "Generacion: 1691 con costo: 0.6114580631256104\n",
      "Generacion: 1701 con costo: 0.6112995743751526\n",
      "Generacion: 1711 con costo: 0.611149251461029\n",
      "Generacion: 1721 con costo: 0.6110017895698547\n",
      "Generacion: 1731 con costo: 0.6108558773994446\n",
      "Generacion: 1741 con costo: 0.6107120513916016\n",
      "Generacion: 1751 con costo: 0.6105670928955078\n",
      "Generacion: 1761 con costo: 0.6104257106781006\n",
      "Generacion: 1771 con costo: 0.6102849841117859\n",
      "Generacion: 1781 con costo: 0.6101431250572205\n",
      "Generacion: 1791 con costo: 0.6099980473518372\n",
      "Generacion: 1801 con costo: 0.6098516583442688\n",
      "Generacion: 1811 con costo: 0.6097055673599243\n",
      "Generacion: 1821 con costo: 0.6095602512359619\n",
      "Generacion: 1831 con costo: 0.6094122529029846\n",
      "Generacion: 1841 con costo: 0.6092652082443237\n",
      "Generacion: 1851 con costo: 0.60912024974823\n",
      "Generacion: 1861 con costo: 0.6089694499969482\n",
      "Generacion: 1871 con costo: 0.6088204979896545\n",
      "Generacion: 1881 con costo: 0.6086757779121399\n",
      "Generacion: 1891 con costo: 0.6085296273231506\n",
      "Generacion: 1901 con costo: 0.6083840131759644\n",
      "Generacion: 1911 con costo: 0.6082371473312378\n",
      "Generacion: 1921 con costo: 0.6080899238586426\n",
      "Generacion: 1931 con costo: 0.6079458594322205\n",
      "Generacion: 1941 con costo: 0.607800304889679\n",
      "Generacion: 1951 con costo: 0.6076546907424927\n",
      "Generacion: 1961 con costo: 0.6075026988983154\n",
      "Generacion: 1971 con costo: 0.6073495149612427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generacion: 1981 con costo: 0.6071782112121582\n",
      "Generacion: 1991 con costo: 0.6070157885551453\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento\n",
    "costo = nn.CrossEntropyLoss()\n",
    "optimizador = torch.optim.SGD(red_pytorch.parameters(), lr = 0.001)\n",
    "epochs = 2000\n",
    "costos_totales = []\n",
    "\n",
    "for i in range(epochs):\n",
    "  y_pred_t = red_pytorch.forward(X_train_t)\n",
    "  c = costo(y_pred_t, y_train_t)\n",
    "  costos_totales.append(c)\n",
    "\n",
    "  if i%10 == 1:\n",
    "    print('Generacion: {} con costo: {}'.format(i,c.item()))\n",
    "\n",
    "  optimizador.zero_grad()\n",
    "  c.backward()\n",
    "  optimizador.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "id": "WFWtwXlIKejT",
    "outputId": "b30487e5-62d7-4261-e460-d3ee31dda4c3"
   },
   "outputs": [],
   "source": [
    "plt.plot(range(epochs), costos_totales)\n",
    "plt.ylabel('Costos')\n",
    "plt.xlabel('Generaciones')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Jw2r3ygBK7wa",
    "outputId": "81049262-36d5-427b-d626-26d2f303bd14"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 1,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0,\n",
       " 0]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predecir\n",
    "predicciones = []\n",
    "\n",
    "with torch.no_grad():\n",
    "  for i, data in enumerate(X_test_t):\n",
    "    y_pred_test = red_pytorch(data)\n",
    "    predicciones.append(y_pred_test.argmax().item())\n",
    "\n",
    "predicciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "t6JelHWDLgKZ",
    "outputId": "50a764cf-715c-48f4-8885-e6a52279fb6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[150   0]\n",
      " [ 80   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.65      1.00      0.79       150\n",
      "           1       1.00      0.01      0.02        81\n",
      "\n",
      "    accuracy                           0.65       231\n",
      "   macro avg       0.83      0.51      0.41       231\n",
      "weighted avg       0.77      0.65      0.52       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Evaluación de testeo\n",
    "print(confusion_matrix(y_test, predicciones))\n",
    "print(classification_report(y_test, predicciones))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OP5DupOSNI4Q"
   },
   "source": [
    "###Crear Modelo con Keras/Tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OeBbXPNRNCvs"
   },
   "outputs": [],
   "source": [
    "#importar modulo\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0gwhNVlONgth"
   },
   "outputs": [],
   "source": [
    "#Crear el modelo\n",
    "\n",
    "red_keras = Sequential()\n",
    "red_keras.add(Dense(8, input_dim = 8, activation= 'relu'))#entrada\n",
    "red_keras.add(Dense(8, activation= 'relu'))\n",
    "red_keras.add(Dense(4, activation= 'relu'))\n",
    "red_keras.add(Dense(1, activation= 'sigmoid'))\n",
    "\n",
    "red_keras.compile(loss = 'binary_crossentropy', optimizer = 'sgd', metrics = ['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jLkM1igSOj0y",
    "outputId": "56f8a4d1-5e89-4a11-b3c6-e01f33137b80"
   },
   "outputs": [],
   "source": [
    "#entrenamiento\n",
    "\n",
    "historial = red_keras.fit(X_train, y_train, epochs = 2000, batch_size = 10, validation_data = (X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zR6yg09cQMfo",
    "outputId": "000cd96b-a049-46f4-fc4b-01f291b500e4"
   },
   "outputs": [],
   "source": [
    "#Evaluación\n",
    "evaluacion = red_keras.evaluate(X_test,y_test)\n",
    "print(\"%s: %.2f%%\" % (red_keras.metrics_names[1], evaluacion[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6XO4RGFeQ_Cz",
    "outputId": "7049e0cf-25b7-4df3-8ae4-9730c6de5bfb"
   },
   "outputs": [],
   "source": [
    "predicciones = red_keras.predict(X_test)\n",
    "predicciones = np.argmax(predicciones, axis=1)\n",
    "\n",
    "print(confusion_matrix(y_test, predicciones))\n",
    "print(classification_report(y_test, predicciones))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 266
    },
    "id": "y4ZWUfI9RW5m",
    "outputId": "b7c7f595-2c7a-4bfe-8886-820bf535342e"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(historial.history[\"loss\"], 'r', marker='.', label = 'loss')\n",
    "ax.plot(historial.history[\"val_loss\"], 'b', marker='.', label = 'validación')\n",
    "ax.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 268
    },
    "id": "QLnNUy_CR76_",
    "outputId": "d48a3f51-dd99-488d-e1d9-3d41557d9ba5"
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "ax.plot(historial.history[\"accuracy\"], 'r', marker='.', label = 'accuracy')\n",
    "ax.plot(historial.history[\"val_accuracy\"], 'b', marker='.', label = 'validación')\n",
    "ax.legend();"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
